{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d583d3d",
   "metadata": {},
   "source": [
    "# LSTM Example\n",
    "This notebook will go through an example of processing SMS text messages and determining if they are spam or not spam.  \n",
    "\n",
    "We will do quite a bit of pre-processing, which I will briefly cover.  Further information in this topic can be found in subsequent courses or in the associated reference links.  \n",
    "\n",
    "The main purpose of this notebook is to show how to use LSTMs on a deep neural network with text data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368029fd",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "The dataset can be found on this website: https://archive.ics.uci.edu/dataset/228/sms+spam+collection.  It consists of 425 spam messages and 3375 non-spam (\"ham\") messages.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bfce28-c530-4e92-826a-08886238b88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for tensorflow with the following code:\n",
    "!pip list\n",
    "#If using a server that does not already include tensorflow, run the install commands for supporting libraries.\n",
    "# !pip install tensorflow==2.14.0\n",
    "# !pip install dm-tree\n",
    "# !pip install toml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ecf1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "\n",
    "# Workshop Functions\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from WKDSS420_functions import * \n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e486ce33",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawInput = pd.read_csv('SMSSpamCollection', sep='\\t', names=['label','message'])\n",
    "print(rawInput.loc[5,'label'], '\\n', rawInput.loc[5,'message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3384c0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('SMSSpamCollection_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b6ba0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[5,'message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c135ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#most texts short, but this one was really long\n",
    "df.loc[1085,'message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6173ed09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed647686",
   "metadata": {},
   "source": [
    "### Tokenize input words and use result in LSTM NN\n",
    "\n",
    "Sources:\n",
    "\n",
    "https://towardsdatascience.com/understanding-lstm-and-its-quick-implementation-in-keras-for-sentiment-analysis-af410fd85b47\n",
    "and \n",
    "https://towardsdatascience.com/an-easy-tutorial-about-sentiment-analysis-with-deep-learning-and-keras-2bf52b9cba91"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013fe43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "\n",
    "#max_words = 5000\n",
    "#max_len = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(df['message'])\n",
    "sequences = tokenizer.texts_to_sequences(df['message'])\n",
    "texts = pad_sequences(sequences, maxlen=100)\n",
    "texts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4719893",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fd21b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'ham':0, 'spam':1}\n",
    "df.loc[:,'label'] = df.loc[:,'label'].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf1eadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[1:5,'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340edde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, \n",
    "    df.loc[:,'label'].values, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c488a1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(y_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8df7fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916fe7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dense, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38b01f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=5000, output_dim=10, input_length=100)) #The embedding layer\n",
    "model.add(LSTM(3)) # More LSTM layers lead to overfitting\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14f5ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409d2c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''  If you get an error stating \"ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type int)\"\n",
    "... then run the code below.  With some libraries, you may need to recast the 4 numpy arrays to \"int\"\n",
    "\n",
    "X_train=np.asarray(X_train).astype(int)\n",
    "y_train=np.asarray(y_train).astype(int)\n",
    "X_test=np.asarray(X_test).astype(int)\n",
    "y_test=np.asarray(y_test).astype(int)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82c66ef-71a7-4fa3-bbd5-2b4e3a0e6ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.asarray(X_train).astype(int)\n",
    "y_train=np.asarray(y_train).astype(int)\n",
    "X_test=np.asarray(X_test).astype(int)\n",
    "y_test=np.asarray(y_test).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c059b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy') \n",
    "model.fit(x = X_train, y = y_train, epochs=25,validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423ff340",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = pd.DataFrame(model.history.history)\n",
    "losses.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c57dd66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
